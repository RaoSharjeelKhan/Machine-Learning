{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaoSharjeelKhan/Machine-Learning/blob/main/LSTM_SMS_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RZOuS9LWQvv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMHwYXHXCar3"
      },
      "outputs": [],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_h508FEClxO"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(train_file_path, sep='\\t',header=0)\n",
        "df_test = pd.read_csv(test_file_path, sep='\\t',header=0)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.isnull().sum(),df_test.isnull().sum()"
      ],
      "metadata": {
        "id": "tcV3TKeGr2Co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.columns=['target','text']\n",
        "df_test.columns=['target','text']\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "Vua8aeB0vMVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zl0XgtKtvYGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.utils import resample"
      ],
      "metadata": {
        "id": "nIILV4WULXa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data=df_train,x='target')"
      ],
      "metadata": {
        "id": "-RQRSlivLgZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We are facing the issue of imbalanced dataset. We cant undersample the mijority class bacause we dont have enough data, \n",
        "#so the only option we have isto upsample the mijority class\n",
        "# separate minority and majority classes\n",
        "df_ham = df_train[df_train.target=='ham']\n",
        "df_spam = df_train[df_train.target=='spam']\n",
        "\n",
        "# upsample minority\n",
        "df_upsampled = resample(df_spam,\n",
        "                          replace=True, # sample with replacement\n",
        "                          n_samples=len(df_ham), # match number in majority class\n",
        "                          random_state=27) # reproducible results\n",
        "\n",
        "# combine majority and upsampled minority\n",
        "df_new = pd.concat([df_ham, df_upsampled])"
      ],
      "metadata": {
        "id": "0XqNvuGsWIG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOMKywn4zReN"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=df_new,x='target')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_new['text_1'] = df_new['text'].str.replace('\\d+', '')\n",
        "df_test['text_1'] = df_test['text'].str.replace('\\d+', '')\n",
        "df_new.head(14)"
      ],
      "metadata": {
        "id": "0bPx9CQgsB2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "def lemmatize_text(text):\n",
        "   return [lemmatizer.lemmatize(w,'v') for w in w_tokenizer.tokenize(text)]\n",
        "df_new['text_2'] =df_new.text_1.apply(lemmatize_text)\n",
        "df_test['text_2'] = df_test.text_1.apply(lemmatize_text)\n",
        "df_new.head(10)"
      ],
      "metadata": {
        "id": "gnUtpPVO6lp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new.target=df_new.target.replace(\"ham\",0)\n",
        "df_test.target=df_test.target.replace(\"ham\",0)\n",
        "df_new.target=df_new.target.replace(\"spam\",1)\n",
        "df_test.target=df_test.target.replace(\"spam\",1)"
      ],
      "metadata": {
        "id": "JjnDvk4q-Cz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=df_new.text_2\n",
        "X_test=df_test.text_2\n",
        "y_train=df_new.target\n",
        "y_test=df_test.target"
      ],
      "metadata": {
        "id": "Gl_fwGZj_j1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! Now we can proceed to the next step."
      ],
      "metadata": {
        "id": "JhiAmPW9Xdsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=tf.keras.preprocessing.text.Tokenizer(\n",
        "    num_words=1000,\n",
        "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "    lower=True,\n",
        "    split=' ',\n",
        "    char_level=False,\n",
        "    oov_token=''\n",
        ")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "word_index=tokenizer.word_index\n",
        "word_index"
      ],
      "metadata": {
        "id": "D8c_MyIahYGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts=\"how are you doing today\"\n",
        "tokenizer.texts_to_sequences([texts])"
      ],
      "metadata": {
        "id": "lkUbJY5llSaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I think taking 40 as max length will be okay"
      ],
      "metadata": {
        "id": "1SsaBYXHmYfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=40\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "#Defining a function that will help us in truncation and padding\n",
        "train_sequences=tokenizer.texts_to_sequences(X_train.values)\n",
        "test_sequences=tokenizer.texts_to_sequences(X_test.values)\n",
        "train_sequence_padded=pad_sequences(train_sequences, truncating='post', padding='post', maxlen=max_len)\n",
        "test_sequence_padded=pad_sequences(test_sequences, truncating='post', padding='post', maxlen=max_len)\n",
        "test_sequence_padded[5]"
      ],
      "metadata": {
        "id": "4blN5m_NmXSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(1000,64,input_length=40),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)), \n",
        "    tf.keras.layers.Dense(64,activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss=tf.losses.BinaryCrossentropy(),\n",
        "              metrics=[tf.metrics.BinaryAccuracy(name='accuracy')])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "x0UXVFa68Go6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_sequence_padded, y_train,  epochs=10,   batch_size=32, \n",
        "                    validation_data=(test_sequence_padded, y_test))"
      ],
      "metadata": {
        "id": "GndZdjHW9S0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9tD9yACG6M9"
      },
      "outputs": [],
      "source": [
        "# function to predict messages based on model\n",
        "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
        "def predict_message(pred_text):\n",
        "  sequences=tokenizer.texts_to_sequences([pred_text])\n",
        "  sequence_padded=pad_sequences(sequences, truncating='post', padding='post', maxlen=max_len)\n",
        "  pred=model.predict(sequence_padded,verbose=0)\n",
        "  if pred>0.5:\n",
        "    prediction=\"spam\"\n",
        "  else:\n",
        "    prediction=\"ham\"\n",
        "  return (prediction)\n",
        "\n",
        "pred_text = \"how are you doing today?\"\n",
        "\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_text = \"wow, is your arm alright. that happened to me one time too\"\n",
        "\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ],
      "metadata": {
        "id": "2eHv-raWDlQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am getting all the predictions right but i think there is something wrong with the testing function. You can check by yourself by predicting the strings given in the function using my model...Thank you\n"
      ],
      "metadata": {
        "id": "zkmd8FaAFMLW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxotov85SjsC"
      },
      "outputs": [],
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won £1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {}
  },
  "nbformat": 4,
  "nbformat_minor": 0
}